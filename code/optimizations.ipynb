{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# TODO: add torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_A = np.array([[3,2],[2,6]])\n",
    "toy_b = np.array([[2],[-8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steepest_descent(A, b, x0, max_iter=int(1e5), tol=1e-5, recompute=None):\n",
    "    \"\"\"\n",
    "    Solving Ax = b or min(0.5xTAx - bTx + c)\n",
    "    Steepest descent is at orthogonal to the previous one in each iteration.\n",
    "    Suitable for scipy sparse and numpy dense arrays.\n",
    "    Using fast iterative update of residual, rounding errors accumulates.\n",
    "\n",
    "    A: dense or sparse matrix\n",
    "    b, x0: column vectors\n",
    "    recompute: number of iterations to recompute the exact residual, infered if not given\n",
    "\n",
    "    returns:\n",
    "        x: final x\n",
    "        r: final residual\n",
    "        num_iter: number of iterations run\n",
    "    \"\"\"\n",
    "    if recompute is None:\n",
    "        recompute = np.sqrt(A.shape[0])\n",
    "    recompute = int(recompute)\n",
    "\n",
    "    x = x0\n",
    "    r = b - A@x\n",
    "    delta = r.T@r\n",
    "    tolerance = tol**2 * delta # when ||r_i|| <= tol * ||r_0||\n",
    "    num_iter = max_iter\n",
    "    for i in range(max_iter):\n",
    "        q = A@r\n",
    "        alpha = delta / (r.T@q)\n",
    "        x = x + alpha *r\n",
    "        if i % recompute == 0:\n",
    "            r = b - A@x\n",
    "        else:\n",
    "            r = r - alpha*q\n",
    "        delta = r.T@r\n",
    "\n",
    "        if delta <= tolerance:\n",
    "            num_iter = i+1\n",
    "            break\n",
    "    return x, r, num_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30  iterations taken to get result  [[ 2. -2.]]  with residual  [[7.84016407e-09 5.22677546e-09]]\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([[-1],[-2]])\n",
    "x, r, num = steepest_descent(toy_A, toy_b, x0, tol=1e-9)\n",
    "print(num, \" iterations taken to get result \", x.T, \" with residual \", r.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CG(A, b, x0, max_iter=int(1e5), tol=1e-5, recompute=None):\n",
    "    \"\"\"\n",
    "    Solving Ax = b or min(0.5xTAx - bTx + c)\n",
    "    Conjugated gradient starts with the first descent direction as d0,\n",
    "    The rest of the directions are all mutually A-orthogonal and can be built from d0,\n",
    "    Thus, one direction only need to descend once\n",
    "    Suitable for scipy sparse and numpy dense arrays.\n",
    "    Using fast iterative update of residual, rounding errors accumulates.\n",
    "\n",
    "    A: dense or sparse matrix\n",
    "    b, x0: column vectors\n",
    "    recompute: number of iterations to recompute the exact residual, infered if not given\n",
    "\n",
    "    returns:\n",
    "        x: final x\n",
    "        r: final residual\n",
    "        num_iter: number of iterations run\n",
    "    \"\"\"\n",
    "    if recompute is None:\n",
    "        recompute = np.sqrt(A.shape[0])\n",
    "    recompute = int(recompute)\n",
    "\n",
    "    x = x0\n",
    "    r = b - A@x\n",
    "    d = r\n",
    "    delta_new = r.T@r\n",
    "    tolerance = tol**2 * delta_new # when ||r_i|| <= tol * ||r_0||\n",
    "    num_iter = max_iter\n",
    "    for i in range(max_iter):\n",
    "        q = A@d\n",
    "        alpha = delta_new / (d.T@q)\n",
    "        x = x + alpha * d\n",
    "        if i % recompute == 0:\n",
    "            r = b - A@x\n",
    "        else:\n",
    "            r = r - alpha*q\n",
    "\n",
    "        delta_old = delta_new\n",
    "        delta_new = r.T@r\n",
    "        beta = delta_new/delta_old\n",
    "        d = r + beta*d\n",
    "        \n",
    "        if delta_new <= tolerance:\n",
    "            num_iter = i+1\n",
    "            break\n",
    "    return x, r, num_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  iterations taken to get result  [[ 2. -2.]]  with residual  [[0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "x0 = np.array([[-1],[-2]])\n",
    "x, r, num = CG(toy_A, toy_b, x0, tol=1e-9)\n",
    "print(num, \" iterations taken to get result \", x.T, \" with residual \", r.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RobertML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
